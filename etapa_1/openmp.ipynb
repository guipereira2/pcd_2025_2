{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means 1D - Implementação com OpenMP (CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook tem a implementação da **etapa 1: versão paralelizada com o uso do OpenMP (CPU)** do K-means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " O que será feito: \n",
    "1. **Gerar os dados** de forma pseudoaleatória e reprodutiva em um formato com 1 coluna e sem cabeçalho. \n",
    "2. **Implementação da opção A (Reduction)**: Criar `kmeans_1d_parallel_reduction.c` paralelizando os laços `assignment_step` e `update_step` usando `#pragma omp reduction`.\n",
    "3. **Compilação e benchmark da versão Reduction**: Executar testes com diferentes configurações de threads e políticas de escalonamento (`static`, `dynamic` com chunks variados) para medir Speedup e Eficiência.\n",
    "4. **Implementar versão paralela com Critical**: Criar `kmeans_1d_parallel_critical.c` usando `#pragma omp critical` no `update_step` como alternativa ao reduction. \n",
    "5. **Compilaçãp e benchmark da versão Critical**: Realizar os testes similares ao feitos para à versão reduction. \n",
    "6. **Analisar desempenho**: Gerar gráficos de Speedup e Eficiência comparando as implementações. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Geração dos dados pseudoaleatórios e reprodutivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será usado a biblioteca `NumPy` para gerar dados sintéticos 1D que serão usados posteriormente no K-means. O processo garante a reprodutibilidade. \n",
    "\n",
    "A geração consiste em: \n",
    "1. Fixar a semente aleatória `np.random.seed(24)`para garantir reprodutibilidade.\n",
    "2. Criar pontos distribuídos em faixas distintas (ex: 0, 10, 20, 30) usando distribuição normal.\n",
    "3. Gerar três conjuntos de teste com tamanhos crescentes:\n",
    "\t- Pequeno: N=10⁴ pontos, K=4 clusters\n",
    "\t- Médio: N=10⁵ pontos, K=8 clusters\n",
    "\t- Grande: N=10⁶ pontos, K=16 clusters\n",
    "\n",
    "4. Selecionar centróides iniciais aleatoriamente dos dados gerados para cada conjunto.\n",
    "5. Embaralhar os pontos usando `np.random.shuffle`\n",
    "6. Converter os dados para DataFrame do pandas e salvar em arquivos CSV (1 coluna, sem cabeçalho, sem índice) usando `to_csv(index=False, header=False)`:\n",
    "\t- `dados_*.csv` contendo os N pontos\n",
    "\t- `centroides_*.csv` contendo os K centróides iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Gerando conjunto: PEQUENO\n",
      "============================================================\n",
      "N = 10,000 pontos\n",
      "K = 4 clusters\n",
      "Centros reais dos clusters: [0, 10, 20, 30]\n",
      "Desvio padrão: 2.0\n",
      "  Cluster 0: ~2,500 pontos ao redor de 0\n",
      "  Cluster 1: ~2,500 pontos ao redor de 10\n",
      "  Cluster 2: ~2,500 pontos ao redor de 20\n",
      "  Cluster 3: ~2,500 pontos ao redor de 30\n",
      "\n",
      "Centróides iniciais escolhidos: [21.93701747 32.87325466  9.31181049 20.97084085]\n",
      "\n",
      "Arquivos salvos:\n",
      "  - ../dados/dados_pequeno.csv\n",
      "  - ../dados/centroides_pequeno.csv\n",
      "\n",
      "============================================================\n",
      "Gerando conjunto: MEDIO\n",
      "============================================================\n",
      "N = 100,000 pontos\n",
      "K = 8 clusters\n",
      "Centros reais dos clusters: [0, 10, 20, 30, 40, 50, 60, 70]\n",
      "Desvio padrão: 2.5\n",
      "  Cluster 0: ~12,500 pontos ao redor de 0\n",
      "  Cluster 1: ~12,500 pontos ao redor de 10\n",
      "  Cluster 2: ~12,500 pontos ao redor de 20\n",
      "  Cluster 3: ~12,500 pontos ao redor de 30\n",
      "  Cluster 4: ~12,500 pontos ao redor de 40\n",
      "  Cluster 5: ~12,500 pontos ao redor de 50\n",
      "  Cluster 6: ~12,500 pontos ao redor de 60\n",
      "  Cluster 7: ~12,500 pontos ao redor de 70\n",
      "\n",
      "Centróides iniciais escolhidos: [39.47531539 69.5562491  28.18520937 10.88519792  8.45586064 63.77584933\n",
      " 44.25381346 22.53041289]\n",
      "\n",
      "Arquivos salvos:\n",
      "  - ../dados/dados_medio.csv\n",
      "  - ../dados/centroides_medio.csv\n",
      "\n",
      "============================================================\n",
      "Gerando conjunto: GRANDE\n",
      "============================================================\n",
      "N = 1,000,000 pontos\n",
      "K = 16 clusters\n",
      "Centros reais dos clusters: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
      "Desvio padrão: 3.0\n",
      "  Cluster 0: ~62,500 pontos ao redor de 0\n",
      "  Cluster 1: ~62,500 pontos ao redor de 10\n",
      "  Cluster 2: ~62,500 pontos ao redor de 20\n",
      "  Cluster 3: ~62,500 pontos ao redor de 30\n",
      "  Cluster 4: ~62,500 pontos ao redor de 40\n",
      "  Cluster 5: ~62,500 pontos ao redor de 50\n",
      "  Cluster 6: ~62,500 pontos ao redor de 60\n",
      "  Cluster 7: ~62,500 pontos ao redor de 70\n",
      "  Cluster 8: ~62,500 pontos ao redor de 80\n",
      "  Cluster 9: ~62,500 pontos ao redor de 90\n",
      "  Cluster 10: ~62,500 pontos ao redor de 100\n",
      "  Cluster 11: ~62,500 pontos ao redor de 110\n",
      "  Cluster 12: ~62,500 pontos ao redor de 120\n",
      "  Cluster 13: ~62,500 pontos ao redor de 130\n",
      "  Cluster 14: ~62,500 pontos ao redor de 140\n",
      "  Cluster 15: ~62,500 pontos ao redor de 150\n",
      "\n",
      "Centróides iniciais escolhidos: [ 11.45646794 153.18055262  60.99803459  98.97781708 151.08079036\n",
      "  20.60569137  39.0150902   28.56126179  61.391215   111.28161918\n",
      "  20.83761704 151.52917925 140.38934594 140.32635456 139.00979665\n",
      "  65.21299071]\n",
      "\n",
      "Arquivos salvos:\n",
      "  - ../dados/dados_grande.csv\n",
      "  - ../dados/centroides_grande.csv\n",
      "\n",
      "============================================================\n",
      "Resumo dos dados gerados\n",
      "============================================================\n",
      "Pequeno: 10,000 pontos, 4 clusters\n",
      "Médio: 100,000 pontos, 8 clusters\n",
      "Grande: 1,000,000 pontos, 16 clusters\n",
      "\n",
      "Todos os arquivos foram salvos na pasta '../dados/'\n"
     ]
    }
   ],
   "source": [
    "# Importar as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Fixar semente para reprodutibilidade\n",
    "np.random.seed(24)\n",
    "\n",
    "def gerar_dados_clusters(N, K, faixas, desvio=2.0, nome_base=''):\n",
    "    \"\"\"\n",
    "    Gera dados 1D com K clusters em faixas distintas\n",
    "    \"\"\"\n",
    "    pontos_por_cluster = N // K\n",
    "    pontos = []\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Gerando conjunto: {nome_base.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"N = {N:,} pontos\")\n",
    "    print(f\"K = {K} clusters\")\n",
    "    print(f\"Centros reais dos clusters: {faixas}\")\n",
    "    print(f\"Desvio padrão: {desvio}\")\n",
    "    \n",
    "    # Gerar pontos ao redor de cada centro\n",
    "    for i, centro in enumerate(faixas):\n",
    "        pontos_cluster = np.random.normal(centro, desvio, pontos_por_cluster)\n",
    "        pontos.extend(pontos_cluster)\n",
    "        print(f\"  Cluster {i}: ~{pontos_por_cluster:,} pontos ao redor de {centro}\")\n",
    "    \n",
    "    # Adicionar pontos restantes (se N não for divisível por K)\n",
    "    pontos_restantes = N - len(pontos)\n",
    "    if pontos_restantes > 0:\n",
    "        centro_extra = np.random.choice(faixas)\n",
    "        pontos_extras = np.random.normal(centro_extra, desvio, pontos_restantes)\n",
    "        pontos.extend(pontos_extras)\n",
    "    \n",
    "    # Converter para array e embaralhar\n",
    "    pontos = np.array(pontos)\n",
    "    np.random.shuffle(pontos)\n",
    "    \n",
    "    # Gerar centróides iniciais (escolher K pontos aleatórios dos dados)\n",
    "    indices = np.random.choice(len(pontos), K, replace=False)\n",
    "    centroides_iniciais = pontos[indices]\n",
    "    \n",
    "    print(f\"\\nCentróides iniciais escolhidos: {centroides_iniciais}\")\n",
    "    \n",
    "    # Converter para DataFrame do pandas\n",
    "    df_dados = pd.DataFrame(pontos)\n",
    "    df_centroides = pd.DataFrame(centroides_iniciais)\n",
    "    \n",
    "    # Salvar em CSV (sem índice, sem cabeçalho) - usando ../ para subir um nível\n",
    "    arquivo_dados = f'../dados/dados_{nome_base}.csv'\n",
    "    arquivo_centroides = f'../dados/centroides_{nome_base}.csv'\n",
    "    \n",
    "    df_dados.to_csv(arquivo_dados, index=False, header=False)\n",
    "    df_centroides.to_csv(arquivo_centroides, index=False, header=False)\n",
    "    \n",
    "    print(f\"\\nArquivos salvos:\")\n",
    "    print(f\"  - {arquivo_dados}\")\n",
    "    print(f\"  - {arquivo_centroides}\")\n",
    "    \n",
    "    return pontos, centroides_iniciais, faixas\n",
    "\n",
    "# Conjunto pequeno: N=10^4, K=4\n",
    "faixas_pequeno = [0, 10, 20, 30]\n",
    "N_pequeno = 10**4\n",
    "K_pequeno = 4\n",
    "\n",
    "dados_pequeno, cent_pequeno, faixas_p = gerar_dados_clusters(\n",
    "    N=N_pequeno,\n",
    "    K=K_pequeno,\n",
    "    faixas=faixas_pequeno,\n",
    "    desvio=2.0,\n",
    "    nome_base='pequeno'\n",
    ")\n",
    "\n",
    "# Conjunto médio: N=10^5, K=8\n",
    "faixas_medio = [0, 10, 20, 30, 40, 50, 60, 70]\n",
    "N_medio = 10**5\n",
    "K_medio = 8\n",
    "\n",
    "dados_medio, cent_medio, faixas_m = gerar_dados_clusters(\n",
    "    N=N_medio,\n",
    "    K=K_medio,\n",
    "    faixas=faixas_medio,\n",
    "    desvio=2.5,\n",
    "    nome_base='medio'\n",
    ")\n",
    "\n",
    "# Conjunto grande: N=10^6, K=16\n",
    "faixas_grande = [i*10 for i in range(16)]  \n",
    "N_grande = 10**6\n",
    "K_grande = 16\n",
    "\n",
    "dados_grande, cent_grande, faixas_g = gerar_dados_clusters(\n",
    "    N=N_grande,\n",
    "    K=K_grande,\n",
    "    faixas=faixas_grande,\n",
    "    desvio=3.0,\n",
    "    nome_base='grande'\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Resumo dos dados gerados\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Pequeno: {N_pequeno:,} pontos, {K_pequeno} clusters\")\n",
    "print(f\"Médio: {N_medio:,} pontos, {K_medio} clusters\")\n",
    "print(f\"Grande: {N_grande:,} pontos, {K_grande} clusters\")\n",
    "print(f\"\\nTodos os arquivos foram salvos na pasta '../dados/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementação da opção A (Reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é a implementação paralela `kmeans_1d_parallel_reduction.c` usando OpenMP com reduction.\n",
    "\n",
    "- **assignment_step_1d:** O laço principal é paralelizado com `#pragma omp parallel for` e usa `reduction(+:sse)` para acumular o SSE. \n",
    "\n",
    "- **update_step_1d:** O laço de acumulação é paralelizado usando `reduction(+:sum[:K], cnt[:K])` para somar pontos e contar elementos de cada cluster. \n",
    "\n",
    "- **Medição de Tempo:** O main usa `omp_get_wtime()` fornecendo medição. \n",
    "\n",
    "- **Agendamento:** Usa `schedule(runtime)` para permitir controle da política de escalonamento (static, dynamic, guided) via variável de ambiente `OMP_SCHEDULE` sem necessidade de recompilar.\n",
    "\n",
    "- **Parâmetros:** Adiciona número de threads como terceiro argumento na linha de comando, configurado via `omp_set_num_threads()`.\n",
    "\n",
    "Os resultados (centróides e SSE) são **idênticos** à versão sequencial, garantindo corretude, mas com **tempo de execução reduzido** proporcionalmente ao número de threads disponíveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans_1d_parallel_reduction.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans_1d_parallel_reduction.c\n",
    "/* kmeans_1d_parallel_reduction.c\n",
    "   K-means 1D com OpenMP usando REDUCTION\n",
    "   - Paraleliza assignment_step com reduction para SSE\n",
    "   - Paraleliza update_step com reduction para sum e count\n",
    "   \n",
    "   Compilar: gcc -O2 -std=c99 -fopenmp kmeans_1d_parallel_reduction.c -o kmeans_1d_parallel_reduction -lm\n",
    "   Uso:      ./kmeans_1d_parallel_reduction dados.csv centroides_iniciais.csv [num_threads] [max_iter=100] [eps=1e-6] [assign.csv] [centroids.csv] [sse_evolution.csv]\n",
    "*/\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "#include <omp.h>\n",
    "\n",
    "/* ---------- util CSV 1D: cada linha tem 1 número ---------- */\n",
    "static int count_rows(const char *path){\n",
    "    FILE *f = fopen(path, \"r\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s\\n\", path); exit(1); }\n",
    "    int rows=0; char line[8192];\n",
    "    while(fgets(line,sizeof(line),f)){\n",
    "        int only_ws=1;\n",
    "        for(char *p=line; *p; p++){\n",
    "            if(*p!=' ' && *p!='\\t' && *p!='\\n' && *p!='\\r'){ only_ws=0; break; }\n",
    "        }\n",
    "        if(!only_ws) rows++;\n",
    "    }\n",
    "    fclose(f);\n",
    "    return rows;\n",
    "}\n",
    "\n",
    "static double *read_csv_1col(const char *path, int *n_out){\n",
    "    int R = count_rows(path);\n",
    "    if(R<=0){ fprintf(stderr,\"Arquivo vazio: %s\\n\", path); exit(1); }\n",
    "    double *A = (double*)malloc((size_t)R * sizeof(double));\n",
    "    if(!A){ fprintf(stderr,\"Sem memoria para %d linhas\\n\", R); exit(1); }\n",
    "    FILE *f = fopen(path, \"r\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s\\n\", path); free(A); exit(1); }\n",
    "    char line[8192];\n",
    "    int r=0;\n",
    "    while(fgets(line,sizeof(line),f)){\n",
    "        int only_ws=1;\n",
    "        for(char *p=line; *p; p++){\n",
    "            if(*p!=' ' && *p!='\\t' && *p!='\\n' && *p!='\\r'){ only_ws=0; break; }\n",
    "        }\n",
    "        if(only_ws) continue;\n",
    "        const char *delim = \",; \\t\";\n",
    "        char *tok = strtok(line, delim);\n",
    "        if(!tok){ fprintf(stderr,\"Linha %d sem valor em %s\\n\", r+1, path); free(A); exit(1); }\n",
    "        A[r] = atof(tok);\n",
    "        r++;\n",
    "        if(r>R) break;\n",
    "    }\n",
    "    fclose(f);\n",
    "    *n_out = R;\n",
    "    return A;\n",
    "}\n",
    "\n",
    "static void write_assign_csv(const char *path, const int *assign, int N){\n",
    "    if(!path) return;\n",
    "    FILE *f = fopen(path, \"w\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s para escrita\\n\", path); return; }\n",
    "    for(int i=0;i<N;i++) fprintf(f, \"%d\\n\", assign[i]);\n",
    "    fclose(f);\n",
    "}\n",
    "\n",
    "static void write_centroids_csv(const char *path, const double *C, int K){\n",
    "    if(!path) return;\n",
    "    FILE *f = fopen(path, \"w\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s para escrita\\n\", path); return; }\n",
    "    for(int c=0;c<K;c++) fprintf(f, \"%.6f\\n\", C[c]);\n",
    "    fclose(f);\n",
    "}\n",
    "\n",
    "/* ---------- k-means 1D PARALELO COM REDUCTION ---------- */\n",
    "\n",
    "/* assignment: para cada X[i], encontra c com menor (X[i]-C[c])^2 \n",
    "   PARALELIZADO: usa reduction para somar SSE */\n",
    "static double assignment_step_1d(const double *X, const double *C, int *assign, int N, int K){\n",
    "    double sse = 0.0;\n",
    "    \n",
    "    #pragma omp parallel for reduction(+:sse) schedule(runtime)\n",
    "    for(int i=0; i<N; i++){\n",
    "        int best = -1;\n",
    "        double bestd = 1e300;\n",
    "        for(int c=0; c<K; c++){\n",
    "            double diff = X[i] - C[c];\n",
    "            double d = diff*diff;\n",
    "            if(d < bestd){ bestd = d; best = c; }\n",
    "        }\n",
    "        assign[i] = best;\n",
    "        sse += bestd;\n",
    "    }\n",
    "    return sse;\n",
    "}\n",
    "\n",
    "/* update: média dos pontos de cada cluster (1D)\n",
    "   PARALELIZADO: usa arrays de reduction para sum e count */\n",
    "static void update_step_1d(const double *X, double *C, const int *assign, int N, int K){\n",
    "    double *sum = (double*)calloc((size_t)K, sizeof(double));\n",
    "    int *cnt = (int*)calloc((size_t)K, sizeof(int));\n",
    "    if(!sum || !cnt){ fprintf(stderr,\"Sem memoria no update\\n\"); exit(1); }\n",
    "    \n",
    "    // Paralelizar usando array reduction\n",
    "    #pragma omp parallel for reduction(+:sum[:K],cnt[:K]) schedule(runtime)\n",
    "    for(int i=0; i<N; i++){\n",
    "        int c = assign[i];\n",
    "        sum[c] += X[i];\n",
    "        cnt[c] += 1;\n",
    "    }\n",
    "    \n",
    "    // Atualizar centróides\n",
    "    for(int c=0; c<K; c++){\n",
    "        if(cnt[c] > 0) C[c] = sum[c] / (double)cnt[c];\n",
    "        else           C[c] = X[0]; // cluster vazio recebe primeiro ponto\n",
    "    }\n",
    "    \n",
    "    free(sum); \n",
    "    free(cnt);\n",
    "}\n",
    "\n",
    "static void kmeans_1d(const double *X, double *C, int *assign,\n",
    "                      int N, int K, int max_iter, double eps,\n",
    "                      int *iters_out, double *sse_out, const char *sse_path)\n",
    "{\n",
    "    // Abrir arquivo para salvar evolução do SSE\n",
    "    FILE *sse_file = NULL;\n",
    "    if(sse_path){\n",
    "        sse_file = fopen(sse_path, \"w\");\n",
    "        if(sse_file) fprintf(sse_file, \"iteration,sse\\n\");\n",
    "    }\n",
    "    \n",
    "    double prev_sse = 1e300;\n",
    "    double sse = 0.0;\n",
    "    int it;\n",
    "    \n",
    "    for(it=0; it<max_iter; it++){\n",
    "        sse = assignment_step_1d(X, C, assign, N, K);\n",
    "        \n",
    "        // Salvar SSE desta iteração\n",
    "        if(sse_file) fprintf(sse_file, \"%d,%.6f\\n\", it, sse);\n",
    "        \n",
    "        /* parada por variação relativa do SSE */\n",
    "        double rel = fabs(sse - prev_sse) / (prev_sse > 0.0 ? prev_sse : 1.0);\n",
    "        if(rel < eps){ it++; break; }\n",
    "        \n",
    "        update_step_1d(X, C, assign, N, K);\n",
    "        prev_sse = sse;\n",
    "    }\n",
    "    \n",
    "    // Fechar arquivo de evolução do SSE\n",
    "    if(sse_file) fclose(sse_file);\n",
    "    \n",
    "    *iters_out = it;\n",
    "    *sse_out = sse;\n",
    "}\n",
    "\n",
    "/* ---------- main ---------- */\n",
    "\n",
    "int main(int argc, char **argv){\n",
    "    if(argc < 3){\n",
    "        printf(\"Uso: %s dados.csv centroides_iniciais.csv [num_threads=4] [max_iter=100] [eps=1e-6] [assign.csv] [centroids.csv] [sse_evolution.csv]\\n\", argv[0]);\n",
    "        printf(\"Obs: arquivos CSV com 1 coluna (1 valor por linha), sem cabeçalho\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    const char *pathX = argv[1];\n",
    "    const char *pathC = argv[2];\n",
    "    int num_threads = (argc>3)? atoi(argv[3]) : 4;\n",
    "    int max_iter = (argc>4)? atoi(argv[4]) : 100;\n",
    "    double eps   = (argc>5)? atof(argv[5]) : 1e-6;\n",
    "    const char *outAssign   = (argc>6)? argv[6] : NULL;\n",
    "    const char *outCentroid = (argc>7)? argv[7] : NULL;\n",
    "    const char *outSSE      = (argc>8)? argv[8] : NULL;\n",
    "    \n",
    "    if(max_iter <= 0 || eps <= 0.0){\n",
    "        fprintf(stderr,\"Parâmetros inválidos: max_iter>0 e eps>0\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    // Configurar número de threads OpenMP\n",
    "    omp_set_num_threads(num_threads);\n",
    "    \n",
    "    int N=0, K=0;\n",
    "    double *X = read_csv_1col(pathX, &N);\n",
    "    double *C = read_csv_1col(pathC, &K);\n",
    "    int *assign = (int*)malloc((size_t)N * sizeof(int));\n",
    "    if(!assign){ fprintf(stderr,\"Sem memoria para assign\\n\"); free(X); free(C); exit(1); }\n",
    "    \n",
    "    double t0 = omp_get_wtime();\n",
    "    int iters = 0; double sse = 0.0;\n",
    "    kmeans_1d(X, C, assign, N, K, max_iter, eps, &iters, &sse, outSSE);\n",
    "    double t1 = omp_get_wtime();\n",
    "    \n",
    "    double ms = (t1 - t0) * 1000.0;\n",
    "    \n",
    "    printf(\"K-means 1D (OpenMP - Reduction)\\n\");\n",
    "    printf(\"N=%d K=%d max_iter=%d eps=%g threads=%d\\n\", N, K, max_iter, eps, num_threads);\n",
    "    printf(\"Iterações: %d | SSE final: %.6f | Tempo: %.1f ms\\n\", iters, sse, ms);\n",
    "    \n",
    "    write_assign_csv(outAssign, assign, N);\n",
    "    write_centroids_csv(outCentroid, C, K);\n",
    "    \n",
    "    free(assign); free(X); free(C);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compilação e benchmark da versão Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta etapa compila o código paralelo e executa testes para avaliar o desempenho com diferentes configurações de threads e políticas de escalonamento.\n",
    "\n",
    "- **Compilação:** O código é compilado com as flags `-O2 -std=c99 -fopenmp -lm`, onde `-fopenmp` habilita o suporte OpenMP e `-O2` otimiza o código para desempenho.\n",
    "\n",
    "- **Baseline Sequencial:** Primeiro, o script executa a versão sequencial para obter o tempo de referência usado nos cálculos de speedup. Este tempo é extraído e armazenado para comparação.\n",
    "\n",
    "- **Configurações Testadas:**\n",
    "\t- **Threads:** 1, 2, 4, 8 (testando escalabilidade)\n",
    "\t- **Políticas de escalonamento:** static, dynamic com chunks (1, 10, 100), guided\n",
    "\t- **Conjunto de dados:** Conjunto grande (N=1M, K=16)\n",
    "\n",
    "- **Controle de Escalonamento:** A variável de ambiente `OMP_SCHEDULE` controla a política de escalonamento em tempo de execução. Como o código usa `schedule(runtime)`, é possível testar diferentes políticas sem recompilar, simplesmente alterando esta variável antes de cada execução.\n",
    "\n",
    "- **Métricas Calculadas:**\n",
    "\t- **Speedup:** Razão entre tempo sequencial e tempo paralelo (T_seq / T_parallel). Indica quantas vezes o código paralelo é mais rápido.\n",
    "\t- **Eficiência:** Speedup normalizado pelo número de threads (Speedup / threads × 100%). Valores próximos a 100% indicam uso eficiente dos recursos de processamento.\n",
    "\n",
    "- **Processo Automatizado:** O script itera por todas as combinações de threads e políticas de escalonamento, executando o programa, extraindo métricas (tempo, iterações, SSE), calculando speedup e eficiência, e salvando tudo em formato CSV.\n",
    "\n",
    "- **Saída:** Os resultados são salvos em `resultados_reduction/benchmark_reduction.csv` contendo: threads, schedule, tempo, speedup, eficiência, iterações e SSE para cada configuração testada. Este arquivo será usado posteriormente para análise e geração de gráficos comparativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tempo sequencial (baseline): 1979.9 ms\n",
      "\n",
      "Iniciando Benchmark - Versão Reduction\n",
      "\n",
      "Testando: threads=1, schedule=static\n",
      "  Tempo: 1376.1 ms | Speedup: 1.4388x | Eficiência: 143.88%\n",
      "Testando: threads=1, schedule=dynamic,1\n",
      "  Tempo: 5476.6 ms | Speedup: 0.3615x | Eficiência: 36.15%\n",
      "Testando: threads=1, schedule=dynamic,10\n",
      "  Tempo: 2260.7 ms | Speedup: 0.8758x | Eficiência: 87.58%\n",
      "Testando: threads=1, schedule=dynamic,100\n",
      "  Tempo: 1887.1 ms | Speedup: 1.0492x | Eficiência: 104.92%\n",
      "Testando: threads=1, schedule=guided\n",
      "  Tempo: 1844.2 ms | Speedup: 1.0736x | Eficiência: 107.36%\n",
      "\n",
      "Testando: threads=2, schedule=static\n",
      "  Tempo: 959.9 ms | Speedup: 2.0626x | Eficiência: 103.13%\n",
      "Testando: threads=2, schedule=dynamic,1\n",
      "  Tempo: 7342.4 ms | Speedup: 0.2697x | Eficiência: 13.48%\n",
      "Testando: threads=2, schedule=dynamic,10\n",
      "  Tempo: 1690.0 ms | Speedup: 1.1715x | Eficiência: 58.58%\n",
      "Testando: threads=2, schedule=dynamic,100\n",
      "  Tempo: 1282.3 ms | Speedup: 1.5440x | Eficiência: 77.20%\n",
      "Testando: threads=2, schedule=guided\n",
      "  Tempo: 977.8 ms | Speedup: 2.0249x | Eficiência: 101.24%\n",
      "\n",
      "Testando: threads=4, schedule=static\n",
      "  Tempo: 666.3 ms | Speedup: 2.9715x | Eficiência: 74.29%\n",
      "Testando: threads=4, schedule=dynamic,1\n",
      "  Tempo: 7402.8 ms | Speedup: 0.2675x | Eficiência: 6.69%\n",
      "Testando: threads=4, schedule=dynamic,10\n",
      "  Tempo: 1269.3 ms | Speedup: 1.5598x | Eficiência: 39.00%\n",
      "Testando: threads=4, schedule=dynamic,100\n",
      "  Tempo: 655.0 ms | Speedup: 3.0227x | Eficiência: 75.57%\n",
      "Testando: threads=4, schedule=guided\n",
      "  Tempo: 534.4 ms | Speedup: 3.7049x | Eficiência: 92.62%\n",
      "\n",
      "Testando: threads=8, schedule=static\n",
      "  Tempo: 1155.8 ms | Speedup: 1.7130x | Eficiência: 21.41%\n",
      "Testando: threads=8, schedule=dynamic,1\n",
      "  Tempo: 6449.4 ms | Speedup: 0.3070x | Eficiência: 3.84%\n",
      "Testando: threads=8, schedule=dynamic,10\n",
      "  Tempo: 2082.8 ms | Speedup: 0.9506x | Eficiência: 11.88%\n",
      "Testando: threads=8, schedule=dynamic,100\n",
      "  Tempo: 1753.8 ms | Speedup: 1.1289x | Eficiência: 14.11%\n",
      "Testando: threads=8, schedule=guided\n",
      "  Tempo: 1350.0 ms | Speedup: 1.4666x | Eficiência: 18.33%\n",
      "\n",
      "Benchmark Concluído!\n",
      "Resultados salvos em: ../resultados/benchmark_reduction.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Compilar a versão paralela com reduction\n",
    "gcc -O2 -std=c99 -fopenmp kmeans_1d_parallel_reduction.c -o kmeans_1d_parallel_reduction -lm\n",
    "\n",
    "# Tentar ler de um arquivo de log se existir, senão executar\n",
    "if [ -f \"../resultados/tempo_grande.txt\" ]; then\n",
    "    tempo_seq=$(grep \"Tempo:\" ../resultados/tempo_grande.txt | grep -oP 'Tempo: \\K[\\d.]+(?= ms)')\n",
    "else\n",
    "    echo \"Executando baseline sequencial...\"\n",
    "    cd ../etapa_0 2>/dev/null || cd ../etapa_0_sequencial 2>/dev/null || mkdir -p ../etapa_0\n",
    "    \n",
    "    # Executar baseline se o executável existir\n",
    "    if [ -f \"kmeans_1d_naive\" ]; then\n",
    "        ./kmeans_1d_naive ../dados/dados_grande.csv ../dados/centroides_grande.csv 100 1e-6 \\\n",
    "            ../resultados/assign_grande.csv ../resultados/centroids_grande.csv ../resultados/sse_evolution_grande.csv \\\n",
    "            | tee ../resultados/tempo_grande.txt\n",
    "        tempo_seq=$(grep \"Tempo:\" ../resultados/tempo_grande.txt | grep -oP 'Tempo: \\K[\\d.]+(?= ms)')\n",
    "    fi\n",
    "    cd - > /dev/null\n",
    "fi\n",
    "\n",
    "# Se ainda não encontrou, usar a própria versão paralela com 1 thread\n",
    "if [ -z \"$tempo_seq\" ]; then\n",
    "    echo \"Usando versão paralela com 1 thread como baseline...\"\n",
    "    baseline_out=$(./kmeans_1d_parallel_reduction ../dados/dados_grande.csv ../dados/centroides_grande.csv \\\n",
    "        1 100 1e-6 \\\n",
    "        ../resultados/assign_baseline.csv ../resultados/centroids_baseline.csv ../resultados/sse_baseline.csv)\n",
    "    \n",
    "    tempo_seq=$(echo \"$baseline_out\" | grep -oP 'Tempo: \\K[\\d.]+(?= ms)')\n",
    "    echo \"$baseline_out\"\n",
    "fi\n",
    "\n",
    "echo \"\"\n",
    "echo \"Tempo sequencial (baseline): ${tempo_seq} ms\"\n",
    "echo \"\"\n",
    "\n",
    "# Arquivo CSV para guardar resultados\n",
    "echo \"threads,schedule,tempo_ms,speedup,eficiencia,iteracoes,sse\" > ../resultados/benchmark_reduction.csv\n",
    "\n",
    "# Configurações de teste\n",
    "threads_list=(1 2 4 8)\n",
    "schedules=(\"static\" \"dynamic,1\" \"dynamic,10\" \"dynamic,100\" \"guided\")\n",
    "\n",
    "echo \"Iniciando Benchmark - Versão Reduction\"\n",
    "echo \"\"\n",
    "\n",
    "# Loop através de diferentes configurações\n",
    "for threads in \"${threads_list[@]}\"; do\n",
    "    for schedule in \"${schedules[@]}\"; do\n",
    "        echo \"Testando: threads=${threads}, schedule=${schedule}\"\n",
    "        \n",
    "        export OMP_SCHEDULE=\"${schedule}\"\n",
    "        \n",
    "        output=$(./kmeans_1d_parallel_reduction ../dados/dados_grande.csv ../dados/centroides_grande.csv \\\n",
    "            ${threads} 100 1e-6 \\\n",
    "            ../resultados/assign_reduction_${threads}_${schedule//,/_}.csv \\\n",
    "            ../resultados/centroids_reduction_${threads}_${schedule//,/_}.csv \\\n",
    "            ../resultados/sse_reduction_${threads}_${schedule//,/_}.csv 2>&1)\n",
    "        \n",
    "        # Extrair métricas - CORRIGIDO: busca especificamente após \"Tempo:\"\n",
    "        tempo=$(echo \"$output\" | grep -oP 'Tempo: \\K[\\d.]+(?= ms)')\n",
    "        iteracoes=$(echo \"$output\" | grep -oP 'Iterações: \\K\\d+')\n",
    "        sse=$(echo \"$output\" | grep -oP 'SSE final: \\K[\\d.]+')\n",
    "        \n",
    "        # Calcular Speedup e Eficiência\n",
    "        if [ ! -z \"$tempo\" ] && [ ! -z \"$tempo_seq\" ]; then\n",
    "            speedup=$(awk \"BEGIN {printf \\\"%.4f\\\", ${tempo_seq} / ${tempo}}\")\n",
    "            eficiencia_pct=$(awk \"BEGIN {printf \\\"%.2f\\\", (${tempo_seq} / ${tempo}) / ${threads} * 100}\")\n",
    "            eficiencia=$(awk \"BEGIN {printf \\\"%.4f\\\", (${tempo_seq} / ${tempo}) / ${threads}}\")\n",
    "        else\n",
    "            speedup=\"0\"\n",
    "            eficiencia=\"0\"\n",
    "            eficiencia_pct=\"0\"\n",
    "        fi\n",
    "        \n",
    "        echo \"  Tempo: ${tempo} ms | Speedup: ${speedup}x | Eficiência: ${eficiencia_pct}%\"\n",
    "        \n",
    "        echo \"${threads},${schedule},${tempo},${speedup},${eficiencia},${iteracoes},${sse}\" >> ../resultados/benchmark_reduction.csv\n",
    "    done\n",
    "    echo \"\"\n",
    "done\n",
    "\n",
    "echo \"Resultados salvos em: ../resultados/benchmark_reduction.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. **Implementar versão paralela com Critical**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é a implementação paralela `kmeans_1d_parallel_critical.c` usando **critical sections** do OpenMP como alternativa ao reduction.\n",
    "\n",
    "- **assignment_step_1d:** O laço principal  é paralelizado com `#pragma omp parallel for`. Para acumular o SSE utiliza `#pragma omp critical` ao invés de reduction.\n",
    "\n",
    "- **update_step_1d:** O laço é paralelizado, mas usa `#pragma omp critical` para proteger as atualizações de `sum[c]` e `cnt[c]`. \n",
    "\n",
    "- **Medição de Tempo:** Usa `omp_get_wtime()` para medição precisa de wall-clock time, igual à versão reduction.\n",
    "\n",
    "- **Agendamento:** Utiliza `schedule(runtime)` para permitir controle via `OMP_SCHEDULE`.\n",
    "\n",
    "Os resultados (centróides e SSE) são **idênticos** às versões sequencial e reduction, mas o **tempo de execução será maior** devido ao overhead das seções críticas, especialmente com muitas threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans_1d_parallel_critical.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans_1d_parallel_critical.c\n",
    "/* kmeans_1d_parallel_critical.c\n",
    "   K-means 1D com OpenMP usando CRITICAL SECTION\n",
    "   - Paraleliza assignment_step com critical para acumular SSE\n",
    "   - Paraleliza update_step com critical para atualizar sum e count\n",
    "   \n",
    "   Compilar: gcc -O2 -std=c99 -fopenmp kmeans_1d_parallel_critical.c -o kmeans_1d_parallel_critical -lm\n",
    "   Uso:      ./kmeans_1d_parallel_critical dados.csv centroides_iniciais.csv [num_threads] [max_iter=100] [eps=1e-6] [assign.csv] [centroids.csv] [sse_evolution.csv]\n",
    "*/\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <string.h>\n",
    "#include <math.h>\n",
    "#include <omp.h>\n",
    "\n",
    "/* ---------- util CSV 1D: cada linha tem 1 número ---------- */\n",
    "static int count_rows(const char *path){\n",
    "    FILE *f = fopen(path, \"r\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s\\n\", path); exit(1); }\n",
    "    int rows=0; char line[8192];\n",
    "    while(fgets(line,sizeof(line),f)){\n",
    "        int only_ws=1;\n",
    "        for(char *p=line; *p; p++){\n",
    "            if(*p!=' ' && *p!='\\t' && *p!='\\n' && *p!='\\r'){ only_ws=0; break; }\n",
    "        }\n",
    "        if(!only_ws) rows++;\n",
    "    }\n",
    "    fclose(f);\n",
    "    return rows;\n",
    "}\n",
    "\n",
    "static double *read_csv_1col(const char *path, int *n_out){\n",
    "    int R = count_rows(path);\n",
    "    if(R<=0){ fprintf(stderr,\"Arquivo vazio: %s\\n\", path); exit(1); }\n",
    "    double *A = (double*)malloc((size_t)R * sizeof(double));\n",
    "    if(!A){ fprintf(stderr,\"Sem memoria para %d linhas\\n\", R); exit(1); }\n",
    "    FILE *f = fopen(path, \"r\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s\\n\", path); free(A); exit(1); }\n",
    "    char line[8192];\n",
    "    int r=0;\n",
    "    while(fgets(line,sizeof(line),f)){\n",
    "        int only_ws=1;\n",
    "        for(char *p=line; *p; p++){\n",
    "            if(*p!=' ' && *p!='\\t' && *p!='\\n' && *p!='\\r'){ only_ws=0; break; }\n",
    "        }\n",
    "        if(only_ws) continue;\n",
    "        const char *delim = \",; \\t\";\n",
    "        char *tok = strtok(line, delim);\n",
    "        if(!tok){ fprintf(stderr,\"Linha %d sem valor em %s\\n\", r+1, path); free(A); exit(1); }\n",
    "        A[r] = atof(tok);\n",
    "        r++;\n",
    "        if(r>R) break;\n",
    "    }\n",
    "    fclose(f);\n",
    "    *n_out = R;\n",
    "    return A;\n",
    "}\n",
    "\n",
    "static void write_assign_csv(const char *path, const int *assign, int N){\n",
    "    if(!path) return;\n",
    "    FILE *f = fopen(path, \"w\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s para escrita\\n\", path); return; }\n",
    "    for(int i=0;i<N;i++) fprintf(f, \"%d\\n\", assign[i]);\n",
    "    fclose(f);\n",
    "}\n",
    "\n",
    "static void write_centroids_csv(const char *path, const double *C, int K){\n",
    "    if(!path) return;\n",
    "    FILE *f = fopen(path, \"w\");\n",
    "    if(!f){ fprintf(stderr,\"Erro ao abrir %s para escrita\\n\", path); return; }\n",
    "    for(int c=0;c<K;c++) fprintf(f, \"%.6f\\n\", C[c]);\n",
    "    fclose(f);\n",
    "}\n",
    "\n",
    "/* ---------- k-means 1D PARALELO COM CRITICAL ---------- */\n",
    "\n",
    "/* assignment: para cada X[i], encontra c com menor (X[i]-C[c])^2 \n",
    "   PARALELIZADO: usa critical section para somar SSE */\n",
    "static double assignment_step_1d(const double *X, const double *C, int *assign, int N, int K){\n",
    "    double sse = 0.0;\n",
    "    \n",
    "    #pragma omp parallel for schedule(runtime)\n",
    "    for(int i=0; i<N; i++){\n",
    "        int best = -1;\n",
    "        double bestd = 1e300;\n",
    "        for(int c=0; c<K; c++){\n",
    "            double diff = X[i] - C[c];\n",
    "            double d = diff*diff;\n",
    "            if(d < bestd){ bestd = d; best = c; }\n",
    "        }\n",
    "        assign[i] = best;\n",
    "        \n",
    "        // Usar critical section para acumular SSE de forma segura\n",
    "        #pragma omp critical\n",
    "        {\n",
    "            sse += bestd;\n",
    "        }\n",
    "    }\n",
    "    return sse;\n",
    "}\n",
    "\n",
    "/* update: média dos pontos de cada cluster (1D)\n",
    "   PARALELIZADO: usa critical section para atualizar sum e count */\n",
    "static void update_step_1d(const double *X, double *C, const int *assign, int N, int K){\n",
    "    double *sum = (double*)calloc((size_t)K, sizeof(double));\n",
    "    int *cnt = (int*)calloc((size_t)K, sizeof(int));\n",
    "    if(!sum || !cnt){ fprintf(stderr,\"Sem memoria no update\\n\"); exit(1); }\n",
    "    \n",
    "    // Paralelizar com critical section para atualizações seguras\n",
    "    #pragma omp parallel for schedule(runtime)\n",
    "    for(int i=0; i<N; i++){\n",
    "        int c = assign[i];\n",
    "        \n",
    "        // Usar critical section para atualizar sum e count\n",
    "        #pragma omp critical\n",
    "        {\n",
    "            sum[c] += X[i];\n",
    "            cnt[c] += 1;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Atualizar centróides\n",
    "    for(int c=0; c<K; c++){\n",
    "        if(cnt[c] > 0) C[c] = sum[c] / (double)cnt[c];\n",
    "        else           C[c] = X[0]; // cluster vazio recebe primeiro ponto\n",
    "    }\n",
    "    \n",
    "    free(sum); \n",
    "    free(cnt);\n",
    "}\n",
    "\n",
    "static void kmeans_1d(const double *X, double *C, int *assign,\n",
    "                      int N, int K, int max_iter, double eps,\n",
    "                      int *iters_out, double *sse_out, const char *sse_path)\n",
    "{\n",
    "    // Abrir arquivo para salvar evolução do SSE\n",
    "    FILE *sse_file = NULL;\n",
    "    if(sse_path){\n",
    "        sse_file = fopen(sse_path, \"w\");\n",
    "        if(sse_file) fprintf(sse_file, \"iteration,sse\\n\");\n",
    "    }\n",
    "    \n",
    "    double prev_sse = 1e300;\n",
    "    double sse = 0.0;\n",
    "    int it;\n",
    "    \n",
    "    for(it=0; it<max_iter; it++){\n",
    "        sse = assignment_step_1d(X, C, assign, N, K);\n",
    "        \n",
    "        // Salvar SSE desta iteração\n",
    "        if(sse_file) fprintf(sse_file, \"%d,%.6f\\n\", it, sse);\n",
    "        \n",
    "        /* parada por variação relativa do SSE */\n",
    "        double rel = fabs(sse - prev_sse) / (prev_sse > 0.0 ? prev_sse : 1.0);\n",
    "        if(rel < eps){ it++; break; }\n",
    "        \n",
    "        update_step_1d(X, C, assign, N, K);\n",
    "        prev_sse = sse;\n",
    "    }\n",
    "    \n",
    "    // Fechar arquivo de evolução do SSE\n",
    "    if(sse_file) fclose(sse_file);\n",
    "    \n",
    "    *iters_out = it;\n",
    "    *sse_out = sse;\n",
    "}\n",
    "\n",
    "/* ---------- main ---------- */\n",
    "\n",
    "int main(int argc, char **argv){\n",
    "    if(argc < 3){\n",
    "        printf(\"Uso: %s dados.csv centroides_iniciais.csv [num_threads=4] [max_iter=100] [eps=1e-6] [assign.csv] [centroids.csv] [sse_evolution.csv]\\n\", argv[0]);\n",
    "        printf(\"Obs: arquivos CSV com 1 coluna (1 valor por linha), sem cabeçalho\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    const char *pathX = argv[1];\n",
    "    const char *pathC = argv[2];\n",
    "    int num_threads = (argc>3)? atoi(argv[3]) : 4;\n",
    "    int max_iter = (argc>4)? atoi(argv[4]) : 100;\n",
    "    double eps   = (argc>5)? atof(argv[5]) : 1e-6;\n",
    "    const char *outAssign   = (argc>6)? argv[6] : NULL;\n",
    "    const char *outCentroid = (argc>7)? argv[7] : NULL;\n",
    "    const char *outSSE      = (argc>8)? argv[8] : NULL;\n",
    "    \n",
    "    if(max_iter <= 0 || eps <= 0.0){\n",
    "        fprintf(stderr,\"Parâmetros inválidos: max_iter>0 e eps>0\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "    \n",
    "    // Configurar número de threads OpenMP\n",
    "    omp_set_num_threads(num_threads);\n",
    "    \n",
    "    int N=0, K=0;\n",
    "    double *X = read_csv_1col(pathX, &N);\n",
    "    double *C = read_csv_1col(pathC, &K);\n",
    "    int *assign = (int*)malloc((size_t)N * sizeof(int));\n",
    "    if(!assign){ fprintf(stderr,\"Sem memoria para assign\\n\"); free(X); free(C); exit(1); }\n",
    "    \n",
    "    double t0 = omp_get_wtime();\n",
    "    int iters = 0; double sse = 0.0;\n",
    "    kmeans_1d(X, C, assign, N, K, max_iter, eps, &iters, &sse, outSSE);\n",
    "    double t1 = omp_get_wtime();\n",
    "    \n",
    "    double ms = (t1 - t0) * 1000.0;\n",
    "    \n",
    "    printf(\"K-means 1D (OpenMP - Critical)\\n\");\n",
    "    printf(\"N=%d K=%d max_iter=%d eps=%g threads=%d\\n\", N, K, max_iter, eps, num_threads);\n",
    "    printf(\"Iterações: %d | SSE final: %.6f | Tempo: %.1f ms\\n\", iters, sse, ms);\n",
    "    \n",
    "    write_assign_csv(outAssign, assign, N);\n",
    "    write_centroids_csv(outCentroid, C, K);\n",
    "    \n",
    "    free(assign); free(X); free(C);\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **Compilação e benchmark da versão Critical**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta etapa compila a versão com seções críticas e executa os mesmos testes da versão reduction.\n",
    "\n",
    "- **Compilação:** O código é compilado com as mesmas flags: `-O2 -std=c99 -fopenmp -lm`.\n",
    "\n",
    "- **Baseline Compartilhado:** Utiliza o mesmo tempo sequencial de referência da versão reduction.\n",
    "\n",
    "- **Configurações Testadas:**\n",
    "\t- **Threads:** 1, 2, 4, 8\n",
    "\t- **Políticas de escalonamento:** static, dynamic (chunks 1, 10, 100), guided\n",
    "\t- **Conjunto de dados:** Conjunto grande (N=1M, K=16)\n",
    "\n",
    "- **Controle de Escalonamento:** A variável `OMP_SCHEDULE` controla a política em tempo de execução via `schedule(runtime)`.\n",
    "\n",
    "- **Métricas Calculadas:**\n",
    "\t- **Speedup:** T_seq / T_parallel\n",
    "\t- **Eficiência:** (Speedup / threads) × 100%\n",
    "\n",
    "- **Comparação Esperada:** Esta versão deve apresentar speedups **menores** e eficiências **piores** que a versão reduction devido ao overhead das seções críticas. A contenção aumenta com mais threads, pois elas competem pelo acesso exclusivo, criando gargalos de serialização.\n",
    "\n",
    "- **Saída:** Os resultados são salvos em `../resultados/benchmark_critical.csv` no mesmo formato da versão reduction, facilitando análises comparativas posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo tempo sequencial do baseline...\n",
      "Tempo sequencial (baseline): 1979.9 ms\n",
      "\n",
      "Iniciando Benchmark - Versão Critical\n",
      "\n",
      "Testando: threads=1, schedule=static\n",
      "  Tempo: 3017.1 ms | Speedup: 0.6562x | Eficiência: 65.62%\n",
      "Testando: threads=1, schedule=dynamic,1\n",
      "  Tempo: 6639.5 ms | Speedup: 0.2982x | Eficiência: 29.82%\n",
      "Testando: threads=1, schedule=dynamic,10\n",
      "  Tempo: 4374.5 ms | Speedup: 0.4526x | Eficiência: 45.26%\n",
      "Testando: threads=1, schedule=dynamic,100\n",
      "  Tempo: 4273.5 ms | Speedup: 0.4633x | Eficiência: 46.33%\n",
      "Testando: threads=1, schedule=guided\n",
      "  Tempo: 4228.8 ms | Speedup: 0.4682x | Eficiência: 46.82%\n",
      "\n",
      "Testando: threads=2, schedule=static\n",
      "  Tempo: 10953.9 ms | Speedup: 0.1807x | Eficiência: 9.04%\n",
      "Testando: threads=2, schedule=dynamic,1\n",
      "  Tempo: 19555.9 ms | Speedup: 0.1012x | Eficiência: 5.06%\n",
      "Testando: threads=2, schedule=dynamic,10\n",
      "  Tempo: 12558.4 ms | Speedup: 0.1577x | Eficiência: 7.88%\n",
      "Testando: threads=2, schedule=dynamic,100\n",
      "  Tempo: 10618.4 ms | Speedup: 0.1865x | Eficiência: 9.32%\n",
      "Testando: threads=2, schedule=guided\n",
      "  Tempo: 12186.5 ms | Speedup: 0.1625x | Eficiência: 8.12%\n",
      "\n",
      "Testando: threads=4, schedule=static\n",
      "  Tempo: 25543.8 ms | Speedup: 0.0775x | Eficiência: 1.94%\n",
      "Testando: threads=4, schedule=dynamic,1\n",
      "  Tempo: 38623.1 ms | Speedup: 0.0513x | Eficiência: 1.28%\n",
      "Testando: threads=4, schedule=dynamic,10\n",
      "  Tempo: 28432.5 ms | Speedup: 0.0696x | Eficiência: 1.74%\n",
      "Testando: threads=4, schedule=dynamic,100\n",
      "  Tempo: 27170.5 ms | Speedup: 0.0729x | Eficiência: 1.82%\n",
      "Testando: threads=4, schedule=guided\n",
      "  Tempo: 26320.7 ms | Speedup: 0.0752x | Eficiência: 1.88%\n",
      "\n",
      "Testando: threads=8, schedule=static\n",
      "  Tempo: 31649.9 ms | Speedup: 0.0626x | Eficiência: 0.78%\n",
      "Testando: threads=8, schedule=dynamic,1\n",
      "  Tempo: 52705.4 ms | Speedup: 0.0376x | Eficiência: 0.47%\n",
      "Testando: threads=8, schedule=dynamic,10\n",
      "  Tempo: 36386.8 ms | Speedup: 0.0544x | Eficiência: 0.68%\n",
      "Testando: threads=8, schedule=dynamic,100\n",
      "  Tempo: 34833.5 ms | Speedup: 0.0568x | Eficiência: 0.71%\n",
      "Testando: threads=8, schedule=guided\n",
      "  Tempo: 34105.9 ms | Speedup: 0.0581x | Eficiência: 0.73%\n",
      "\n",
      "Resultados salvos em: ../resultados/benchmark_critical.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Compilar a versão paralela com critical\n",
    "gcc -O2 -std=c99 -fopenmp kmeans_1d_parallel_critical.c -o kmeans_1d_parallel_critical -lm\n",
    "\n",
    "# Ler tempo sequencial do baseline \n",
    "echo \"Lendo tempo sequencial do baseline...\"\n",
    "tempo_seq=$(grep \"Tempo:\" ../resultados/tempo_grande.txt 2>/dev/null | grep -oP 'Tempo: \\K[\\d.]+(?= ms)')\n",
    "\n",
    "if [ -z \"$tempo_seq\" ]; then\n",
    "    echo \"Usando baseline da versão reduction...\"\n",
    "    tempo_seq=$(head -2 ../resultados/benchmark_reduction.csv | tail -1 | cut -d',' -f3)\n",
    "fi\n",
    "\n",
    "echo \"Tempo sequencial (baseline): ${tempo_seq} ms\"\n",
    "echo \"\"\n",
    "\n",
    "# Arquivo CSV para guardar resultados\n",
    "echo \"threads,schedule,tempo_ms,speedup,eficiencia,iteracoes,sse\" > ../resultados/benchmark_critical.csv\n",
    "\n",
    "# Configurações de teste \n",
    "threads_list=(1 2 4 8)\n",
    "schedules=(\"static\" \"dynamic,1\" \"dynamic,10\" \"dynamic,100\" \"guided\")\n",
    "\n",
    "echo \"Iniciando Benchmark - Versão Critical\"\n",
    "echo \"\"\n",
    "\n",
    "# Loop através de diferentes configurações\n",
    "for threads in \"${threads_list[@]}\"; do\n",
    "    for schedule in \"${schedules[@]}\"; do\n",
    "        echo \"Testando: threads=${threads}, schedule=${schedule}\"\n",
    "        \n",
    "        export OMP_SCHEDULE=\"${schedule}\"\n",
    "        \n",
    "        output=$(./kmeans_1d_parallel_critical ../dados/dados_grande.csv ../dados/centroides_grande.csv \\\n",
    "            ${threads} 100 1e-6 \\\n",
    "            ../resultados/assign_critical_${threads}_${schedule//,/_}.csv \\\n",
    "            ../resultados/centroids_critical_${threads}_${schedule//,/_}.csv \\\n",
    "            ../resultados/sse_critical_${threads}_${schedule//,/_}.csv 2>&1)\n",
    "        \n",
    "        # Extrair métricas\n",
    "        tempo=$(echo \"$output\" | grep -oP 'Tempo: \\K[\\d.]+(?= ms)')\n",
    "        iteracoes=$(echo \"$output\" | grep -oP 'Iterações: \\K\\d+')\n",
    "        sse=$(echo \"$output\" | grep -oP 'SSE final: \\K[\\d.]+')\n",
    "        \n",
    "        # Calcular Speedup e Eficiência\n",
    "        if [ ! -z \"$tempo\" ] && [ ! -z \"$tempo_seq\" ]; then\n",
    "            speedup=$(awk \"BEGIN {printf \\\"%.4f\\\", ${tempo_seq} / ${tempo}}\")\n",
    "            eficiencia_pct=$(awk \"BEGIN {printf \\\"%.2f\\\", (${tempo_seq} / ${tempo}) / ${threads} * 100}\")\n",
    "            eficiencia=$(awk \"BEGIN {printf \\\"%.4f\\\", (${tempo_seq} / ${tempo}) / ${threads}}\")\n",
    "        else\n",
    "            speedup=\"0\"\n",
    "            eficiencia=\"0\"\n",
    "            eficiencia_pct=\"0\"\n",
    "        fi\n",
    "        \n",
    "        echo \"  Tempo: ${tempo} ms | Speedup: ${speedup}x | Eficiência: ${eficiencia_pct}%\"\n",
    "        \n",
    "        echo \"${threads},${schedule},${tempo},${speedup},${eficiencia},${iteracoes},${sse}\" >> ../resultados/benchmark_critical.csv\n",
    "    done\n",
    "    echo \"\"\n",
    "done\n",
    "\n",
    "echo \"Resultados salvos em: ../resultados/benchmark_critical.csv\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
